{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with LLaMa-3 70B, Mistral8x7b and gemma7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2 doc embeddings, each with a dimensionality of 384.\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    \"this is one document\",\n",
    "    \"and another document\"\n",
    "]\n",
    "\n",
    "embeddings = embed_model.embed_documents(docs)\n",
    "\n",
    "print(f\"We have {len(embeddings)} doc embeddings, each with \"\n",
    "      f\"a dimensionality of {len(embeddings[0])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = \"8a73267f-d64d-4d53-a5ae-0a241afd5517\"\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index initialize\n",
    "index_name = \"final-llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=len(embeddings[0]),\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vijay/anaconda3/envs/llm/lib/python3.12/site-packages/datasets/load.py:1486: FutureWarning: The repository for wikipedia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wikipedia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"wikipedia\", \"20220301.simple\", split='train[:5000]')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'gpt2'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "tiktoken.encoding_for_model('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    # print(tokens)\n",
    "    return len(tokens)\n",
    "\n",
    "tiktoken_len(\"hello I am a chunk of text and using the tiktoken_len function \"\n",
    "             \"we can find the length of this chunk of text in tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "embed = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:29<00:00, 33.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_limit = 100\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i, record in enumerate(tqdm(data)):\n",
    "    # first get metadata fields for this record\n",
    "    metadata = {\n",
    "        'wiki-id': str(record['id']),\n",
    "        'source': record['url'],\n",
    "        'title': record['title']\n",
    "    }\n",
    "    # now we create chunks from the record text\n",
    "    record_texts = text_splitter.split_text(record['text'])\n",
    "    # create individual metadata dicts for each chunk\n",
    "    record_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(record_texts)]\n",
    "    # append these to current batches\n",
    "    texts.extend(record_texts)\n",
    "    metadatas.extend(record_metadatas)\n",
    "    # if we have reached the batch_limit we can add texts\n",
    "    if len(texts) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "        embeds = embed.embed_documents(texts)\n",
    "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "\n",
    "if len(texts) > 0:\n",
    "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "    embeds = embed.embed_documents(texts)\n",
    "    index.upsert(vectors=zip(ids, embeds, metadatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 19907}},\n",
       " 'total_vector_count': 19907}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector store and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "embed = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = \"8a73267f-d64d-4d53-a5ae-0a241afd5517\"\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vijay/anaconda3/envs/llm/lib/python3.12/site-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index_name=\"final-llm\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  WikiQA.zip\n",
      "  inflating: WikiQA.tsv              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!unzip WikiQA.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file\n",
    "df = pd.read_csv('WikiQA.tsv', delimiter='\\t')\n",
    "\n",
    "# Remove duplicate questions\n",
    "df = df.drop_duplicates(subset=['Question'])\n",
    "\n",
    "# Reduce to desired columns\n",
    "df = df[['QuestionID', 'Question', 'Sentence']]\n",
    "\n",
    "# Select the first 100 questions\n",
    "df = df.head(100)\n",
    "\n",
    "# Save the processed file\n",
    "df.to_csv('processed_WikiQA.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q0</td>\n",
       "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
       "      <td>African immigration to the United States refer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>A partly submerged glacier cave on Perito More...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2</td>\n",
       "      <td>How are the directions of the velocity and for...</td>\n",
       "      <td>In physics , circular motion is a movement of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q3</td>\n",
       "      <td>how large were early jails</td>\n",
       "      <td>A prison (from Old French prisoun), also known...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q4</td>\n",
       "      <td>how a water pump works</td>\n",
       "      <td>A small, electrically powered pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Q95</td>\n",
       "      <td>how long is tekken blood vengeance movie</td>\n",
       "      <td>is a 2011 Japanese 3D computer-animated film b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Q96</td>\n",
       "      <td>how can hoa collect unpaid fees on property</td>\n",
       "      <td>For a discussion of nonprofit, voluntary neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Q97</td>\n",
       "      <td>how big can texel guinea pigs become</td>\n",
       "      <td>A prize-winning lilac-and-white Silkie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Q98</td>\n",
       "      <td>how are public schools funded</td>\n",
       "      <td>State schools (also known as public schools or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Q99</td>\n",
       "      <td>how are ribosomes made</td>\n",
       "      <td>The ribosome assembles polymeric protein molec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionID                                           Question  \\\n",
       "0          Q0    HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US   \n",
       "1          Q1                      how are glacier caves formed?   \n",
       "2          Q2  How are the directions of the velocity and for...   \n",
       "3          Q3                         how large were early jails   \n",
       "4          Q4                             how a water pump works   \n",
       "..        ...                                                ...   \n",
       "95        Q95           how long is tekken blood vengeance movie   \n",
       "96        Q96        how can hoa collect unpaid fees on property   \n",
       "97        Q97               how big can texel guinea pigs become   \n",
       "98        Q98                      how are public schools funded   \n",
       "99        Q99                             how are ribosomes made   \n",
       "\n",
       "                                             Sentence  \n",
       "0   African immigration to the United States refer...  \n",
       "1   A partly submerged glacier cave on Perito More...  \n",
       "2   In physics , circular motion is a movement of ...  \n",
       "3   A prison (from Old French prisoun), also known...  \n",
       "4                  A small, electrically powered pump  \n",
       "..                                                ...  \n",
       "95  is a 2011 Japanese 3D computer-animated film b...  \n",
       "96  For a discussion of nonprofit, voluntary neigh...  \n",
       "97             A prize-winning lilac-and-white Silkie  \n",
       "98  State schools (also known as public schools or...  \n",
       "99  The ribosome assembles polymeric protein molec...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_WikiQA.tsv', delimiter='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|██████████| 20/20 [06:31<00:00, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Outputs: ['Cross section of sclerenchyma fibers in plant ground tissue', 'Terminator 3: Rise of the Machines (commonly abbreviated as T3) is a 2003 science fiction action film directed by Jonathan Mostow and starring Arnold Schwarzenegger , Nick Stahl , Claire Danes and Kristanna Loken .', 'TLC is an American girl group whose repertoire spanned R&B , hip hop , soul , funk , and new jack swing .', 'Radial engine timing and cam mechanism.', 'A natural arch produced by the erosion of differentially weathered rock in Jebel Kharaz, Jordan']\n",
      "Mistral Outputs: ['Epithelial tissues are joined together by a variety of methods, depending on the specific type of epithelial tissue. Generally, epithelial cells adhere to each other through specialized junctions, which include tight junctions, adherens junctions, and desmosomes.\\n\\nTight junctions, also known as occluding junctions, are the most apically located junctions and form a virtually impermeable barrier to the passage of solutes between cells. They are composed of transmembrane proteins called claudins and occludins, which interact with similar proteins on adjacent cells to form a seal.\\n\\nAdherens junctions are located just below tight junctions and are responsible for maintaining the integrity of the epithelial sheet. They consist of transmembrane cadherin proteins that interact with actin filaments in the cytoskeleton of adjacent cells.\\n\\nDesmosomes, also known as macula adherens, are located at the basolateral region of epithelial cells and provide strong adhesion between cells. They are composed of transmembrane glycoproteins called desmogleins and desmocollins, which interact with intermediate filaments in the cytoskeleton of adjacent cells.\\n\\nOverall, these junctions allow epithelial tissues to form a continuous barrier that protects the underlying tissues and organs, while also allowing for the selective transport of molecules and ions.\\n\\nReferences:\\n\\n- \"Epithelial Tissue.\" In Encyclopædia Britannica, Nov. 11, 2021, <https://www.britannica.com/science/epithelial-tissue>.\\n- \"Cell Junctions.\" In Encyclopædia Britannica, Nov. 11, 2021, <https://www.britannica.com/science/cell-junction>.\\n- \"Histology of Epithelial Tissues.\" In StatPearls [Internet]., U.S. National Library of Medicine, 2021, <https://www.ncbi.nlm.nih.gov/books/NBK535323/>.\\n- \"Cell Junctions.\" In BioNinja, <https://bioninja.com.au/structure-function/cell-structure/cell-junctions.html>.\\n- \"Cell Junctions.\" In Biology Dictionary, <https://biologydictionary.net/cell-junctions/>.', \"I don't have the exact age of Arnold Schwarzenegger in Terminator 3, but I can tell you that the movie was released in 2003. Schwarzenegger was born on July 30, 1947, so he would have been around 56 years old during the filming of Terminator 3. However, the character he plays, the Terminator, is not subject to human aging.\\n\\nSources:\\n[{'chunk': 0.0, 'source': 'https://en.wikipedia.org/wiki/Arnold%20Schwarzenegger', 'title': 'Arnold Schwarzenegger', 'wiki-id': '32355'}]\", 'I don\\'t have real-time information on the heights of individuals, but I can tell you that TLC is an American girl group whose members are Tionne \"T-Boz\" Watkins, Rozonda \"Chilli\" Thomas, and the late Lisa \"Left Eye\" Lopes. According to various sources, T-Boz\\'s height is around 5 feet 2 inches (157 cm), and Chilli\\'s height is around 5 feet 2.5 inches (158 cm). Lisa \"Left Eye\" Lopes\\' height was around 5 feet 1 inch (155 cm). Keep in mind that these heights can vary slightly depending on the source.\\n\\nReferences:\\n- \"Tionne Watkins.\" In _Women in Rock, Revised and Updated 2nd ed._, edited by Holly George-Warren, 351-352. New York: Omnibus Press, 2011.\\n- \"Rozonda Thomas.\" In _Women in Rock, Revised and Updated 2nd ed._, edited by Holly George-Warren, 352-353. New York: Omnibus Press, 2011.\\n- \"Lisa Lopes.\" In _Women in Rock, Revised and Updated 2nd ed._, edited by Holly George-Warren, 353-354. New York: Omnibus Press, 2011.', 'Aircraft radial engines are a type of internal combustion engine that are built using a configuration where the cylinders are arranged radially around a central crankshaft, resembling the spokes of a wheel. They are called \"radial\" engines because of this radial arrangement of the cylinders.\\n\\nThe construction of a radial engine involves several steps:\\n\\n1. **Cylinder Manufacturing**: The cylinders are typically made from aluminum or steel and are machined to precise tolerances. They consist of a cylindrical barrel, a piston, and a head that contains the valves and spark plugs.\\n\\n2. **Crankshaft Assembly**: The crankshaft is the central component of the engine around which the cylinders are arranged. It is typically made from steel and is machined to create precise journal and crankpin dimensions.\\n\\n3. **Cylinder Assembly**: The cylinders are attached to the crankshaft using various methods, such as bolts or studs. The pistons are installed in the cylinders and connected to the crankshaft using connecting rods.\\n\\n4. **Valve Train Assembly**: The valve train consists of the intake and exhaust valves, valve springs, and related components. These are installed in the cylinder head and connected to the camshaft, which operates the valves.\\n\\n5. **Accessory Drive**: Radial engines often have various accessories, such as fuel pumps, oil pumps, magnetos, and generators. These are driven by the engine and are typically mounted on the accessory drive housing.\\n\\n6. **Final Assembly**: The engine is then assembled, including the installation of the cylinders, crankshaft, valve train, accessory drive, and other components. The engine is then tested and inspected to ensure it meets the required specifications.\\n\\nRadial engines were commonly used in aircraft due to their simplicity, durability, and high power-to-weight ratio. However, they have largely been replaced by more modern engine designs, such as turboprop and jet engines.\\n\\nSources:\\n\\n* <https://simple.wikipedia.org/wiki/Engine>\\n* <https://simple.wikipedia.org/wiki/Diesel_engine>', \"I don't have information on plant gases directly slowing erosion. However, plants can help reduce erosion through a process called photosynthesis, where they absorb carbon dioxide and release oxygen. This process helps reduce the amount of carbon dioxide in the atmosphere, which is a greenhouse gas contributing to climate change. Indirectly, by slowing climate change, plants can help reduce the rate of erosion.\\n\\nChanges in climate, such as increased temperature and shifts in precipitation patterns, can affect erosion rates. Warmer temperatures can lead to increased weathering and soil erosion, while changes in precipitation can result in more frequent and intense storms, which can increase runoff and erosion.\\n\\nPlants can help mitigate these effects by increasing the soil's ability to retain water and reducing runoff. Plant roots hold the soil together, reducing the likelihood of soil erosion due to wind or water. Additionally, plants like trees and shrubs can help reduce wind speed near the ground, further reducing the potential for wind erosion.\\n\\nSources:\\n\\n* <https://simple.wikipedia.org/wiki/Global_warming>\\n* <https://simple.wikipedia.org/wiki/Wind>\\n* <https://simple.wikipedia.org/wiki/Stream>\"]\n",
      "LLaMA Outputs: ['Epithelial tissues are joined together by specialized structures called tight junctions, adherens junctions, and desmosomes. These structures help to hold the epithelial cells together, forming a strong and cohesive layer.\\n\\nTight junctions are impermeable seals that fuse the membranes of adjacent cells, creating a barrier to the free movement of molecules. Adherens junctions are protein-based structures that help to anchor cells together, while desmosomes are small, button-like structures that hold cells together.\\n\\nThese structures are essential for maintaining the integrity of epithelial tissues, which form the lining of organs, glands, and other body surfaces.\\n\\nSource: [1] Alberts, B., Johnson, A., Lewis, J., Raff, M., Roberts, K., & Walter, P. (2002). Molecular Biology of the Cell. 5th edition. New York: Garland Science.', 'The question is about Arnold Schwarzenegger, not the provided context about Ronald Reagan, George Lucas, or Scott Bakula. \\n\\nTo answer your question, in Terminator 3: Rise of the Machines (2003), Arnold Schwarzenegger was 56 years old.', 'According to various sources, the heights of the members of TLC are:\\n\\n* Tionne \"T-Boz\" Watkins: 5 feet 4 inches (162.56 cm) [1]\\n* Lisa \"Left Eye\" Lopes: 5 feet 2 inches (157.48 cm) [2]\\n* Rozonda \"Chilli\" Thomas: 5 feet 4 inches (162.56 cm) [3]\\n\\nPlease note that these heights are based on available information and may not be exact or up-to-date.\\n\\nSources:\\n\\n[1] Various online sources, including Wikipedia and celebrity height websites.\\n[2] Various online sources, including Wikipedia and celebrity height websites.\\n[3] Various online sources, including Wikipedia and celebrity height websites.', 'Aircraft radial engines are a type of internal combustion engine that uses a radial configuration, where the cylinders are arranged in a circular pattern around the crankshaft. Here\\'s a brief overview of how they\\'re built:\\n\\n**Cylinder Construction:**\\n\\n* Each cylinder is typically made of aluminum alloy or steel and has a bore (inner diameter) of around 4-6 inches (10-15 cm).\\n* The cylinders are arranged in a circular pattern, with the crankshaft at the center.\\n* The cylinders are connected to the crankcase, which houses the crankshaft and camshaft.\\n\\n**Crankshaft and Camshaft:**\\n\\n* The crankshaft is a long, rod-like component that converts the up-and-down motion of the pistons into rotary motion.\\n* The camshaft is a rod with lobes that open and close the valves that allow air and fuel into the cylinders and exhaust gases out of the cylinders.\\n\\n**Pistons and Connecting Rods:**\\n\\n* The pistons are connected to the crankshaft via connecting rods, which convert the up-and-down motion of the pistons into rotary motion.\\n* The pistons are typically made of aluminum alloy or steel and have rings that seal the cylinder walls and prevent oil from leaking out.\\n\\n**Valves and Valve Train:**\\n\\n* The valves are operated by the camshaft and allow air and fuel into the cylinders and exhaust gases out of the cylinders.\\n* The valve train consists of the valves, valve springs, and valve guides that keep the valves in place.\\n\\n**Ignition System:**\\n\\n* The ignition system typically uses a magneto or an electrical ignition system to generate a spark that ignites the fuel-air mixture in the cylinders.\\n\\n**Cooling System:**\\n\\n* The cooling system typically uses air cooling, where the engine is cooled by airflow around the cylinders and cylinder heads.\\n\\n**Assembly and Testing:**\\n\\n* The engine is assembled by attaching the cylinders to the crankcase, installing the crankshaft and camshaft, and connecting the pistons and connecting rods.\\n* The engine is then tested to ensure it meets performance and safety standards.\\n\\nSources:\\n\\n* \"Radial Engine\" by Wikipedia (https://en.wikipedia.org/wiki/Radial_engine)\\n* \"Aircraft Engine Construction\" by Aircraft Systems for Pilots (https://www.aopa.org/news-and-media/all-news/2019/june/aircraft-systems-for-pilots-aircraft-engine-construction)\\n\\nPlease note that this is a simplified overview, and the actual construction of an aircraft radial engine involves many more details and complexities.', 'Plant gases, specifically roots and vegetation, can slow erosion in several ways:\\n\\n1. **Roots hold soil in place**: Plant roots act as anchors, holding the soil in place and preventing it from being washed or blown away.\\n2. **Vegetation reduces runoff**: Vegetation helps to absorb rainfall, reducing the amount of water that flows over the land and causing erosion.\\n3. **Soil stabilization**: Plant roots and stems help to stabilize the soil, making it more resistant to erosion.\\n4. **Increased infiltration**: Vegetation increases the infiltration of water into the soil, reducing surface runoff and erosion.\\n5. **Soil binding**: Plant roots and organic matter help to bind the soil particles together, making it more resistant to erosion.\\n\\nThese mechanisms can help to reduce soil erosion, especially in areas prone to landslides, floods, or wind erosion.\\n\\nSource: Various studies on soil erosion and vegetation, including research by the USDA and the International Soil Conservation Organization.']\n",
      "GEMMA Outputs: ['Epithelial tissues are joined together by **adherens junctions, desmosomes, and gap junctions**.\\n\\n* **Adherens junctions** hold epithelial cells together by forming strong mechanical connections between their plasma membranes.\\n\\n\\n* **Desmosomes** provide strong mechanical connections between adjacent epithelial cells, preventing them from pulling apart.\\n\\n\\n* **Gap junctions** allow for electrical and chemical communication between adjacent epithelial cells, ensuring coordinated function of the tissue.', 'The provided text does not contain any information regarding Arnold Schwarzenegger or the Terminator movies, so I am unable to answer this question from the given context.', 'The provided text does not contain any information regarding the heights of the members of TLC, so I am unable to answer this question from the given context.', 'The provided text does not contain any information regarding the construction or building of aircraft radial engines, so I am unable to answer this question from the given context.', 'The provided text does not contain any information regarding how plant gases can slow erosion, so I am unable to answer this question from the given context.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv('processed_WikiQA.tsv', delimiter='\\t')\n",
    "df = df.sample(20, random_state=123)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "# Placeholder lists for storing outputs\n",
    "mistral_outs = []\n",
    "llama_outs = []\n",
    "gemma_outs = []\n",
    "real_outs = []\n",
    "\n",
    "chat_mistral = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"mixtral-8x7b-32768\")\n",
    "chat_llama = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"llama3-70b-8192\")\n",
    "chat_gemma = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"gemma-7b-it\")\n",
    "\n",
    "# Function for each model\n",
    "def call_mistral(query, relevant_documents):\n",
    "    # Mistral\n",
    "    \n",
    "    matched_info = ' '.join(item.page_content for item in relevant_documents)\n",
    "    sources = [item.metadata for item in relevant_documents]\n",
    "    context = f\"Information: {matched_info} and the sources: {sources}\"\n",
    "    sys_prompt = f\"\"\"\n",
    "    Instructions:\n",
    "    - Be helpful and answer questions concisely. If you don't know the answer, say 'I don't know'\n",
    "    - Utilize the context provided for accurate and specific information.\n",
    "    - Incorporate your preexisting knowledge to enhance the depth and relevance of your response.\n",
    "    - Cite your sources\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    system = \"You are a helpful assistant.\"\n",
    "    human = \"{text}\"\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "    chain = prompt | chat_mistral\n",
    "    prompt_ = query\n",
    "    \n",
    "    return chain.invoke({\"text\": prompt_ + \"\\n\" + sys_prompt}).content\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def call_llama(query, relevant_documents):\n",
    "    # Implement or simulate LLM response\n",
    "    matched_info = ' '.join(item.page_content for item in relevant_documents)\n",
    "    sources = [item.metadata for item in relevant_documents]\n",
    "    context = f\"Information: {matched_info} and the sources: {sources}\"\n",
    "    sys_prompt = f\"\"\"\n",
    "    Instructions:\n",
    "    - Be helpful and answer questions concisely. If you don't know the answer, say 'I don't know'\n",
    "    - Utilize the context provided for accurate and specific information.\n",
    "    - Incorporate your preexisting knowledge to enhance the depth and relevance of your response.\n",
    "    - Cite your sources\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    system = \"You are a helpful assistant.\"\n",
    "    human = \"{text}\"\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "    chain = prompt | chat_llama\n",
    "    prompt_ = query\n",
    "    \n",
    "    return chain.invoke({\"text\": prompt_ + \"\\n\" + sys_prompt}).content\n",
    "\n",
    "def call_gemma(query, relevant_documents):\n",
    "    # Implement or simulate LLM response\n",
    "    matched_info = ' '.join(item.page_content for item in relevant_documents)\n",
    "    sources = [item.metadata for item in relevant_documents]\n",
    "    context = f\"Information: {matched_info} and the sources: {sources}\"\n",
    "    sys_prompt = f\"\"\"\n",
    "    Instructions:\n",
    "    - Be helpful and answer questions concisely. If you don't know the answer, say 'I don't know'\n",
    "    - Utilize the context provided for accurate and specific information.\n",
    "    - Incorporate your preexisting knowledge to enhance the depth and relevance of your response.\n",
    "    - Cite your sources\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    system = \"You are a helpful assistant.\"\n",
    "    human = \"{text}\"\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "    chain = prompt | chat_gemma\n",
    "    prompt_ = query\n",
    "    \n",
    "    return chain.invoke({\"text\": prompt_ + \"\\n\" + sys_prompt}).content\n",
    "\n",
    "    \n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing questions\"):\n",
    "    query = str(row['Question'])\n",
    "    \n",
    "    # Store real output\n",
    "    real_outs.append(str(row['Sentence']))\n",
    "    \n",
    "    # Simulate a vectorstore search (this function must be defined elsewhere)\n",
    "    relevant_documents = vectorstore.similarity_search(\n",
    "                            query,  # our search query\n",
    "                            k=3  # return 3 most relevant docs\n",
    "                        )\n",
    "    \n",
    "    # Call each model and store their outputs\n",
    "    mistral_outs.append(call_mistral(query, relevant_documents))\n",
    "    llama_outs.append(call_llama(query, relevant_documents))\n",
    "    gemma_outs.append(call_gemma(query, relevant_documents))\n",
    "    \n",
    "# Optionally, print the outputs to verify\n",
    "print(\"Real Outputs:\", real_outs[:5])\n",
    "print(\"Mistral Outputs:\", mistral_outs[:5])\n",
    "print(\"LLaMA Outputs:\", llama_outs[:5])\n",
    "print(\"GEMMA Outputs:\", gemma_outs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vijay/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vijay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/vijay/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral\n",
      "BLEU Score: {'bleu': 0.013220144898102472, 'precisions': [0.05640033176665745, 0.014178482068390326, 0.007548224769359799, 0.005060444194545966], 'brevity_penalty': 1.0, 'length_ratio': 8.0917225950783, 'translation_length': 3617, 'reference_length': 447}\n",
      "METEOR Score: {'meteor': 0.18360866517814425}\n",
      "BERTScore-precision: 0.5501263305544853\n",
      "BERTScore-recall: 0.6753357648849487\n",
      "BERTScore-f1: 0.6052185118198394\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Llama\n",
      "BLEU Score: {'bleu': 0.012660943619327073, 'precisions': [0.055486670799752016, 0.014971927635683094, 0.007532956685499058, 0.00410612760581175], 'brevity_penalty': 1.0, 'length_ratio': 7.217002237136465, 'translation_length': 3226, 'reference_length': 447}\n",
      "METEOR Score: {'meteor': 0.17164903365354653}\n",
      "BERTScore-precision: 0.5953129217028618\n",
      "BERTScore-recall: 0.6720740914344787\n",
      "BERTScore-f1: 0.6287255764007569\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Gemma\n",
      "BLEU Score: {'bleu': 0.00975817185442108, 'precisions': [0.07874762808349146, 0.01160541586073501, 0.004930966469428008, 0.002012072434607646], 'brevity_penalty': 1.0, 'length_ratio': 2.3579418344519016, 'translation_length': 1054, 'reference_length': 447}\n",
      "METEOR Score: {'meteor': 0.11302312559209718}\n",
      "BERTScore-precision: 0.6271613478660584\n",
      "BERTScore-recall: 0.6606465578079224\n",
      "BERTScore-f1: 0.6419614017009735\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import evaluate as E\n",
    "import numpy as np\n",
    "\n",
    "bleu = E.load(\"bleu\")\n",
    "meteor_metric = E.load(\"meteor\")\n",
    "bertscore_metric = E.load(\"bertscore\")\n",
    "\n",
    "def test_metrics_2b(references, predictions):\n",
    "\n",
    "  bleu_score = bleu.compute(predictions=predictions, references=references)\n",
    "  meteor_score = meteor_metric.compute(predictions=predictions, references=references)\n",
    "  bertscore_score = bertscore_metric.compute(predictions=predictions, references=references, lang=\"de\")\n",
    "\n",
    "  bs_pre = np.mean(np.array(bertscore_score['precision']))\n",
    "  bs_recall = np.mean(np.array(bertscore_score['recall']))\n",
    "  bs_f1 = np.mean(np.array(bertscore_score['f1']))\n",
    "\n",
    "\n",
    "  print(f'BLEU Score: {bleu_score}')\n",
    "  print(f'METEOR Score: {meteor_score}')\n",
    "  print(f'BERTScore-precision: {bs_pre}')\n",
    "  print(f'BERTScore-recall: {bs_recall}')\n",
    "  print(f'BERTScore-f1: {bs_f1}')\n",
    "  \n",
    "print(\"Mistral\")\n",
    "test_metrics_2b(real_outs, mistral_outs)\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Llama\")\n",
    "test_metrics_2b(real_outs, llama_outs)\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Gemma\")\n",
    "test_metrics_2b(real_outs, gemma_outs)\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completed ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born American scientist. He worked on theoretical physics. He developed the theory of relativity. He received the Nobel Prize in Physics in 1921 for theoretical physics.\\n\\nHis famous equation is  (E = energy, m = mass, c = speed of light (energy = mass X speed of light²).\\n\\nAt the start of his career, Einstein didn't think that Newtonian mechanics was enough to bring together the laws of classical mechanics and the laws of the electromagnetic field. Between 1902–1909 he made the theory of special relativity to fix it. Einstein also thought that Isaac Newton's idea of gravity was not completely correct. So, he extended his ideas on special relativity to include gravity. In 1916, he published a paper on general relativity with his theory of gravitation.\\n\\nIn 1933, Einstein was visiting the United States but in Germany, Adolf Hitler and the Nazis came to power (this is before World War II). Einstein, being of Jewish ethnicity, did not return to Germany due to Hitler’s anti-Semitic policies. He lived in the United States and became an American citizen in 1940. On the beginning of World War II, he sent a letter to President Franklin D. Roosevelt explaining to him that Germany was in the process of making a nuclear weapon; so Einstein recommended that the U.S. should also make one. This led to the Manhattan Project, and the U.S. became the first nation in history to create and use the atomic bomb (not on Germany but on Japan). Einstein and other physicists like Richard Feynman who worked on the Manhattan Project later regretted that the bomb was used on Japan.\\n\\nEinstein lived in Princeton and was one of the first members invited to the Institute for Advanced Study, where he worked for the remainder of his life.\\n\\nHe is now thought to be one of the greatest scientists of all time.\", metadata={'chunk': 0.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}),\n",
       " Document(page_content='Other websites \\n\\n What Did Albert Einstein Invent?\\n\\n1879 births\\n1955 deaths\\n \\nCardiovascular disease deaths in the United States\\nDeaths from aortic aneurysm\\nGerman Nobel Prize winners\\nGerman physicists\\nJewish academics\\nJewish American academics\\nJewish American scientists\\nJewish German academics\\nJewish German scientists\\nJewish Nobel Prize winners\\nJewish scientists\\nNaturalized citizens of the United States\\nNobel Prize in Physics winners\\nPeople from Ulm\\nRefugees from Nazism\\nSwiss Jews\\nSwiss scientists\\nAmerican theoretical physicists\\nEducators from New Jersey', metadata={'chunk': 16.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'}),\n",
       " Document(page_content='He is now thought to be one of the greatest scientists of all time.\\n\\nHis contributions helped lay the foundations for all modern branches of physics, including quantum mechanics and relativity.\\n\\nLife\\n\\nEarly life \\nEinstein was born in Ulm, Württemberg, Germany, on 14 March 1879. His family was Jewish, but was not very religious. However, later in life Einstein became very interested in his Judaism. Einstein did not begin speaking until he was 2 years old. According to his younger sister, Maja, \"He had such difficulty with language that those around him feared he would never learn\". When Einstein was around 4 years old, his father gave him a magnetic compass. He tried hard to understand how the needle could seem to move itself so that it always pointed north. The needle was in a closed case, so clearly nothing like wind could be pushing the needle around, and yet it moved. So in this way Einstein became interested in studying science and mathematics. His compass gave him ideas to explore the world of science.\\n\\nWhen he became older, he went to school in Switzerland. After he graduated, he got a job in the patent office there. While he was working there, he wrote the papers that first made him famous as a great scientist.\\n\\nEinstein married with a 20-year-old Serbian woman Mileva Marić in January 1903.\\n\\nIn 1917, Einstein became very sick with an illness that almost killed him, fortunately he survived. His cousin Elsa Löwenthal nursed him back to health. After this happened, Einstein divorced Mileva in 14 February 1919, and married Elsa on 2 June 1919.', metadata={'chunk': 1.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who was Albert Einstein?\"\n",
    "\n",
    "relevant_documents = vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Albert Einstein (14 March 1879 – 18 April 1955) was a German-born American scientist. He worked on theoretical physics. He developed the theory of relativity. He received the Nobel Prize in Physics in 1921 for theoretical physics.\\n\\nHis famous equation is  (E = energy, m = mass, c = speed of light (energy = mass X speed of light²).\\n\\nAt the start of his career, Einstein didn't think that Newtonian mechanics was enough to bring together the laws of classical mechanics and the laws of the electromagnetic field. Between 1902–1909 he made the theory of special relativity to fix it. Einstein also thought that Isaac Newton's idea of gravity was not completely correct. So, he extended his ideas on special relativity to include gravity. In 1916, he published a paper on general relativity with his theory of gravitation.\\n\\nIn 1933, Einstein was visiting the United States but in Germany, Adolf Hitler and the Nazis came to power (this is before World War II). Einstein, being of Jewish ethnicity, did not return to Germany due to Hitler’s anti-Semitic policies. He lived in the United States and became an American citizen in 1940. On the beginning of World War II, he sent a letter to President Franklin D. Roosevelt explaining to him that Germany was in the process of making a nuclear weapon; so Einstein recommended that the U.S. should also make one. This led to the Manhattan Project, and the U.S. became the first nation in history to create and use the atomic bomb (not on Germany but on Japan). Einstein and other physicists like Richard Feynman who worked on the Manhattan Project later regretted that the bomb was used on Japan.\\n\\nEinstein lived in Princeton and was one of the first members invited to the Institute for Advanced Study, where he worked for the remainder of his life.\\n\\nHe is now thought to be one of the greatest scientists of all time.\", metadata={'chunk': 0.0, 'source': 'https://simple.wikipedia.org/wiki/Albert%20Einstein', 'title': 'Albert Einstein', 'wiki-id': '2138'})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_info = ' '.join(item.page_content for item in relevant_documents)\n",
    "sources = [item.metadata for item in relevant_documents]\n",
    "context = f\"Information: {matched_info} and the sources: {sources}\"\n",
    "sys_prompt = f\"\"\"\n",
    "Instructions:\n",
    "- Be helpful and answer questions concisely. If you don't know the answer, say 'I don't know'\n",
    "- Utilize the context provided for accurate and specific information.\n",
    "- Incorporate your preexisting knowledge to enhance the depth and relevance of your response.\n",
    "- Cite your sources\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
